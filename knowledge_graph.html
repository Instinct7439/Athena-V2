<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #222222;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#FF6B6B", "font": {"color": "white"}, "id": "exam proctoring system researc.txt", "label": "exam proctoring system researc.txt", "shape": "dot", "size": 73, "title": "exam proctoring system researc.txt\nType: paper\nConnections: 21"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "assisted Gaze", "label": "assisted Gaze", "shape": "dot", "size": 16, "title": "assisted Gaze\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "text", "label": "text", "shape": "dot", "size": 16, "title": "text\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "user verification", "label": "user verification", "shape": "dot", "size": 16, "title": "user verification\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "clever face", "label": "clever face", "shape": "dot", "size": 16, "title": "clever face\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "By combining automated monitoring with intelligent violation", "label": "By combining automated monitoring with intelligent violation", "shape": "dot", "size": 13, "title": "By combining automated monitoring with intelligent violation\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "voice", "label": "voice", "shape": "dot", "size": 13, "title": "voice\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "user", "label": "user", "shape": "dot", "size": 13, "title": "user\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "time by", "label": "time by", "shape": "dot", "size": 16, "title": "time by\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "This approach", "label": "This approach", "shape": "dot", "size": 13, "title": "This approach\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "gaze estimation and phone", "label": "gaze estimation and phone", "shape": "dot", "size": 13, "title": "gaze estimation and phone\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "assisted gaze", "label": "assisted gaze", "shape": "dot", "size": 16, "title": "assisted gaze\nType: methods\nConnections: 2"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "gaze estimation", "label": "gaze estimation", "shape": "dot", "size": 13, "title": "gaze estimation\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "By using the continuous", "label": "By using the continuous", "shape": "dot", "size": 13, "title": "By using the continuous\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "text detection", "label": "text detection", "shape": "dot", "size": 13, "title": "text detection\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "effective method", "label": "effective method", "shape": "dot", "size": 13, "title": "effective method\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "automated method", "label": "automated method", "shape": "dot", "size": 13, "title": "automated method\nType: methods\nConnections: 1"}, {"color": "#4ECDC4", "font": {"color": "white"}, "id": "face detection", "label": "face detection", "shape": "dot", "size": 16, "title": "face detection\nType: methods\nConnections: 2"}, {"color": "#95E1D3", "font": {"color": "white"}, "id": "microphone", "label": "microphone", "shape": "dot", "size": 13, "title": "microphone\nType: hardware\nConnections: 1"}, {"color": "#95E1D3", "font": {"color": "white"}, "id": "webcam", "label": "webcam", "shape": "dot", "size": 13, "title": "webcam\nType: hardware\nConnections: 1"}, {"color": "#95E1D3", "font": {"color": "white"}, "id": "camera", "label": "camera", "shape": "dot", "size": 13, "title": "camera\nType: hardware\nConnections: 1"}, {"color": "#C7CEEA", "font": {"color": "white"}, "id": "OpenCV", "label": "OpenCV", "shape": "dot", "size": 16, "title": "OpenCV\nType: software\nConnections: 2"}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "assisted Gaze"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "text"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "user verification"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "clever face"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "By combining automated monitoring with intelligent violation"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "voice"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "user"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "time by"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "This approach"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "gaze estimation and phone"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "assisted gaze"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "gaze estimation"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "By using the continuous"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "text detection"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "effective method"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "automated method"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "face detection"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "microphone"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "webcam"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "camera"}, {"arrows": "to", "from": "exam proctoring system researc.txt", "label": "contains", "title": "contains\n", "to": "OpenCV"}, {"arrows": "to", "from": "assisted Gaze", "label": "detects", "title": "detects\nWe present an AI-assisted gaze detection system, which allows proctors to navigate between different", "to": "assisted gaze"}, {"arrows": "to", "from": "text", "label": "detects", "title": "detects\nThe system includes five basic components that continuously estimate the key behavior cues: user ver", "to": "user verification"}, {"arrows": "to", "from": "clever face", "label": "detects", "title": "detects\nWith the assistance of our system\u0027s clever face detection algorithms, instructors may efficiently id", "to": "face detection"}, {"arrows": "to", "from": "time by", "label": "proposes", "title": "proposes\nThe proposed system leverages computer vision techniques using OpenCV and Media Pipe to monitor stud", "to": "OpenCV"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"enabled": true, "stabilization": {"enabled": true, "iterations": 100}, "barnesHut": {"gravitationalConstant": -8000, "centralGravity": 0.3, "springLength": 200, "springConstant": 0.04}}, "interaction": {"hover": true, "tooltipDelay": 100}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>